{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ENOhwRYofkW3",
        "FKdw-k9IgiLo",
        "06sqC-6nZThU"
      ],
      "authorship_tag": "ABX9TyPRoKhvs5c8omYSpHAc5HRA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justcme/PerformanceSpecs/blob/main/I_NewCriteriaAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Lipid Panel Assays Performance Recommendations\n",
        "\n",
        "Aim to add known biological variability, then NEW allowed imprecision and bias (as proportional bias) to given \"true\" values, to determine the effect on variability of risk classification."
      ],
      "metadata": {
        "id": "_9T2VaL1Fwee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SETUP"
      ],
      "metadata": {
        "id": "1Og253ECcLjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OS"
      ],
      "metadata": {
        "id": "9R9VUIVvGQUe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpubywtBFIq_",
        "outputId": "f69c5bd4-417c-4552-b8d9-2f47ff59419c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/LipidPerf/from_Pandas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "xDokOY5WIcu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "import random\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "VSJUwh6cId8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA"
      ],
      "metadata": {
        "id": "rAziTdPTIeV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_base = pd.read_csv(\"Base/df_base_new.csv\")  #Original Lipid Data\n",
        "PCE_coeffs = pd.read_csv(\"Base/PCE_coeffs.csv\")   #Coefficients for Pooled Cohort Equation calculation\n",
        "TAE = pd.read_csv('Base/TAEnew_df.csv', index_col = 0)   #Allowable error and BV lookup table\n",
        "df0 = pd.read_csv('Base/df0.csv')"
      ],
      "metadata": {
        "id": "iG7JjLnAFZX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TAE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "T2j4ouT9IBjw",
        "outputId": "41827570-4467-4380-c305-d7c931152a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              BV    PB    CV   SD\n",
              "Parameter                        \n",
              "TC         0.053  0.02  0.03  NaN\n",
              "HDL        0.058  0.04  0.03  1.7\n",
              "TG         0.200  0.04  0.03  NaN\n",
              "dLDL       0.083  0.04  0.04  NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88b72f79-ed36-4cf2-a5fe-9836458d6f55\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BV</th>\n",
              "      <th>PB</th>\n",
              "      <th>CV</th>\n",
              "      <th>SD</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Parameter</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TC</th>\n",
              "      <td>0.053</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HDL</th>\n",
              "      <td>0.058</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>1.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TG</th>\n",
              "      <td>0.200</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dLDL</th>\n",
              "      <td>0.083</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88b72f79-ed36-4cf2-a5fe-9836458d6f55')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88b72f79-ed36-4cf2-a5fe-9836458d6f55 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88b72f79-ed36-4cf2-a5fe-9836458d6f55');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Global Variables"
      ],
      "metadata": {
        "id": "r_94R0sEopH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = ['TC','HDL','TG','dLDL']\n",
        "BLipTypes = ['cLDL','NHDL','dLDL']\n",
        "\n",
        "#PCE Variables\n",
        "age = df_base['age']\n",
        "SBP = df_base['SBP']\n",
        "BPRx = df_base['BPRx']\n",
        "BPRxn = df_base['BPRxn']\n",
        "smoker = df_base['smoker']\n",
        "DM = df_base['DM']"
      ],
      "metadata": {
        "id": "daim_C5fokUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FUNCTIONS"
      ],
      "metadata": {
        "id": "ENOhwRYofkW3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Add Variability"
      ],
      "metadata": {
        "id": "7P7JamGyqSIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Seeds2 = [334, 376,  81, 213, 163, 441, 417, 332,  24, 445, 295, 420, 461,\n",
        "       446, 185, 472, 430,  92,  99, 250, 136,  94, 337, 332,  24, 174,\n",
        "       324, 479, 322, 456,  31, 279, 379, 123, 262, 394,  75, 169,  76,\n",
        "       133, 339, 471, 304, 285, 339, 481, 227,  97, 294, 425, 189, 168,\n",
        "       227,  38, 160, 467,  14, 116,  99, 474,  89, 282, 158,  33, 330,\n",
        "       332, 493,  81, 218, 326, 341, 378,  64, 176,  67, 340, 365, 405,\n",
        "       129, 237, 488, 203, 264, 471,  76, 110, 180, 385,  81, 157, 233,\n",
        "       110, 236, 116, 134,  97, 144, 154, 497, 230,  34, 296,  98, 350,\n",
        "       443,  63, 244, 350, 229, 293, 473, 484, 322, 411, 304, 186,  24,\n",
        "       291, 144, 191, 396, 421, 199, 328, 263, 317,  11, 363, 106, 437,\n",
        "       276, 182, 256, 406, 379,  51, 313,  13,  79, 293, 311, 162, 214,\n",
        "       312, 466, 105, 336, 421, 255, 426,  40, 469, 381, 118, 466, 131,\n",
        "       452, 411, 408, 491, 398,  33, 170, 407, 130,  18,   3, 225,   3,\n",
        "       422, 114,  42, 426, 498, 473,  14, 456, 179, 175,  84,  77,  48,\n",
        "        97, 295, 455, 176,  12, 100, 198, 379,  78, 383, 178, 263,  81,\n",
        "       488, 411, 343, 204, 419,  18, 187, 342, 414, 246, 353, 160, 317,\n",
        "       411, 473, 232, 250, 277, 284, 127, 162, 493, 179, 339,  97, 295,\n",
        "       259, 432,  86, 154,  12, 476,   9, 352,  37, 402, 295, 364,  71,\n",
        "       200, 384, 461, 305, 107, 315, 240,  88, 371, 210, 328, 466, 361,\n",
        "       378,  85, 480, 150, 267, 275, 289, 256,  93, 272, 167,  41,  80,\n",
        "       118, 308, 410, 137, 201, 292, 366, 310, 208,   3,  73,  27,  67,\n",
        "       235, 328, 254, 482, 221,  39, 174,  70, 248, 398, 150,  78, 295,\n",
        "       324, 476, 299, 107, 364, 154, 335, 345, 106, 472, 255, 153, 484,\n",
        "       402,  96, 354, 183, 186, 320, 472, 235, 499, 244,  96, 435, 400,\n",
        "       202, 455, 186, 410, 447, 475, 141, 486, 274,  25, 318, 224, 436,\n",
        "         5,  43, 230, 246, 270,  12, 444, 454,  58, 164, 476,  78, 368,\n",
        "        31, 489, 189, 487, 306, 257,  61,  59,  38, 276, 184, 332, 185,\n",
        "        14,  36, 247, 344, 303,  90, 341, 455,  94, 294, 429, 147, 141,\n",
        "       176, 334, 407, 463, 242, 390,  42, 122, 196, 202, 240, 214,  52,\n",
        "        45, 167, 426, 164,  37,  36, 292, 216, 148, 460,  25, 400, 200,\n",
        "       399, 157,  77,  18, 142,  86, 101, 226, 483,  96]"
      ],
      "metadata": {
        "id": "DQWdmGAMvJ1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Seeds1 = Seeds2[1::2]"
      ],
      "metadata": {
        "id": "v4hip2gaP4D2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AddVarGen(df, parameters, PB, variability_types, replicate):\n",
        "  \"\"\"Adds given error types sequentially to given parameters.\n",
        "  Number of Seeds required for RandomState generation = number of parameters*number of replicates.\n",
        "  Seeds array should be created before calling function, and saved for validation of analysis.\"\"\"\n",
        "\n",
        "  \"\"\"The norm.ppf function calculates is the inverse of the cumulative distribution function (CDF) of the standard normal distribution.\n",
        "  ppf stands for percent point function, which is another name for the quantile function.\n",
        "  random_sample selects a random number in the half-open interval [0,1). 1 Might occur due to rounding.\n",
        "  Initially included 0 and 1 but this results in extreme values. Numpy rounds after 16 decimals so I used 15 decimals to create the included range, excluding 0 and 1\n",
        "  providing a RandomState means the pseudo-random numbers generated will be the same each time the code is run. The number selected is meaningless. It just provides a starting point.\n",
        "  The RandomState number should be changed 5 times to get 5 iterations of the error scenarios.\n",
        "  Using (loc = mean, scale = SD) you can specify the mean and SD of the distribution instead of the default standard distribution.\"\"\"\n",
        "\n",
        "  \n",
        "  newdf = df.copy()\n",
        "  lp = len(parameters)\n",
        "  lv = len(variability_types)\n",
        "\n",
        "  for n,p in enumerate(parameters):\n",
        "    if PB == 0 or p == 'dLDL':\n",
        "      p2 = p\n",
        "    else:\n",
        "      p2 = f'{p}_PB{PB}'\n",
        "\n",
        "\n",
        "    newdf.loc[:,p] = df_base.loc[:,p2]\n",
        "\n",
        "    for k,e in enumerate(variability_types):\n",
        "      pos = lp*lv*replicate + (lv*n +k)\n",
        "\n",
        "      if lv == 1:\n",
        "        a = np.random.RandomState(Seeds1[pos])\n",
        "      else:\n",
        "        a = np.random.RandomState(Seeds2[pos])\n",
        "        \n",
        "      if p == 'HDL' and e == 'CV':\n",
        "        V = df_base.loc[:,f'HDL_CV{PB}']\n",
        "      else:\n",
        "        V = TAE.loc[p,e]\n",
        "\n",
        "\n",
        "      newdf.loc[:,p] = norm.ppf(a.uniform(1e-16,0.9999999999999999,8506), loc = newdf.loc[:,p], scale = V*newdf.loc[:,p]).astype('int')\n",
        "\n",
        "    #To deal with values <0, make them = 1\n",
        "    newdf.loc[:,p] = np.select(condlist = [newdf.loc[:,p]<0, newdf.loc[:,p]>=0],\n",
        "                               choicelist = [1, newdf.loc[:,p]],\n",
        "                               default = np.nan)\n",
        "  \n",
        "  return newdf"
      ],
      "metadata": {
        "id": "M9pSbtjeO0f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Calculate and create columns for variable PCE terms and sum them"
      ],
      "metadata": {
        "id": "jxvy8dXRqZvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def AddSum(newdf):\n",
        "  \"\"\"This function creates columns for the variable terms in the PCE calculation and sums them\"\"\"\n",
        "\n",
        "  HDL = newdf['HDL']\n",
        "  TC = newdf['TC']\n",
        "\n",
        "  variableterms = ['TotalChol', 'AgeTotalChol','HDLChol', 'AgeHDLChol']\n",
        "  variables = [np.log(TC), np.log(age)*np.log(TC), np.log(HDL), np.log(age)*np.log(HDL)]\n",
        "  variablecoeffs = ['CTotalChol', 'CAgeTotalChol','CHDLChol', 'CAgeHDLChol']\n",
        "\n",
        "  for t in range(4):\n",
        "    newdf.loc[:,variableterms[t]] = variables[t]*df_base[variablecoeffs[t]]\n",
        "  newdf.loc[:,'add_sum'] = newdf.loc[:,variableterms].sum(axis=1)\n",
        "  \n",
        "  return newdf"
      ],
      "metadata": {
        "id": "IfxZ9tKrqijq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Pooled Cohort Equation (PCE)"
      ],
      "metadata": {
        "id": "FKdw-k9IgiLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def PCEcalc(interum_sum, add_sum, meanterms, S10):\n",
        "  terms = interum_sum + add_sum\n",
        "  PCE = 100*(1 - S10 ** (np.e ** (terms - meanterms)))\n",
        "  return PCE"
      ],
      "metadata": {
        "id": "SF2ne61OgkmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Calculate and create LDL-C, non-HDL-C and PCE Columns"
      ],
      "metadata": {
        "id": "QHy5ut6aa5_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Calcs(df):\n",
        "  \"\"\"This function calculates LDL-C using the Friedewald equation, non-HDL-C,\n",
        "  and the ASCVD risk using the pooled cohort equation (PCE) from the American Heart Association.\"\"\"\n",
        "\n",
        "  newdf = df.copy()\n",
        "  HDL = newdf['HDL']\n",
        "  TC = newdf['TC']\n",
        "  TG = newdf['TG']\n",
        "    \n",
        "  newdf.loc[:,'NHDL'] = TC - HDL\n",
        "  NHDL = newdf.loc[:,'NHDL']\n",
        "\n",
        "  # To calculate LDL-C: where TG<=400, use Friedewald, where >400, use Sampson  \n",
        "  newdf.loc[:,'cLDL'] = np.select(condlist = [newdf.loc[:,'TG']<=400, newdf.loc[:,'TG']>400],\n",
        "                                  choicelist = [TC - HDL - TG/5, TC/0.948 - HDL/0.971 - (TG/8.56 + (TG*NHDL)/2140 - (TG**2)/16100) - 9.44],\n",
        "                                  default = np.nan)  \n",
        "\n",
        "  newdf.loc[:,'PCE'] = newdf.apply(lambda x: PCEcalc(x.interum_sum, x.add_sum, x.MeanTerms, x.S10), axis=1)\n",
        "\n",
        "    \n",
        "  return newdf"
      ],
      "metadata": {
        "id": "CNwQ2e_TYJSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Risk Group Determination"
      ],
      "metadata": {
        "id": "AqTrLRNSbG9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Groups(df):\n",
        "  \"\"\"This function determines the Risk Group (A-D) based on LDL-C and non-HDL-C and creates a column for each.\"\"\"\n",
        "\n",
        "  newdf = df.copy()\n",
        "  LDL = newdf['cLDL']\n",
        "  NHDL = newdf['NHDL']\n",
        "  PCE = newdf['PCE']\n",
        "  TG = newdf['TG']\n",
        "\n",
        "  newdf.loc[:,'Lgroup'] = np.nan\n",
        "  newdf.loc[:,'Lgroup'] = np.select(condlist=[(PCE<7.5) | (LDL<70),\n",
        "                                    (PCE >=20) | (LDL >=190),\n",
        "                                    (LDL >=70) & (LDL <160) & (TG <175),\n",
        "                                    (LDL >=160) | (TG >=175)],\n",
        "                          choicelist=['A','D', 'B', 'C'],\n",
        "                          default=np.nan)\n",
        "    \n",
        "  newdf.loc[:,'Ngroup'] = np.nan\n",
        "  newdf.loc[:,'Ngroup'] = np.select(condlist=[(PCE<7.5) | (NHDL<90),\n",
        "                                     (PCE >=20) | (NHDL >=220),\n",
        "                                     (NHDL >=90) & (NHDL <190) & (TG <175),\n",
        "                                     (NHDL >=190) | (TG >=175)],\n",
        "                           choicelist=['A','D', 'B', 'C'],\n",
        "                           default=np.nan)\n",
        "\n",
        "  return newdf"
      ],
      "metadata": {
        "id": "eIHmDKQadnFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Call all functions to complete new databases"
      ],
      "metadata": {
        "id": "hafw2r9-NBGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def AddCols(df,parameters, PB, variability_types, replicate):\n",
        "  \"\"\"This function adds variability to the lipid results and then calculates the terms for PCE calculation that are dependent on these.\n",
        "    It then sums those terms.\"\"\"\n",
        "\n",
        "#Create a Dataframe\n",
        "  newdf = df[['ID','S10','MeanTerms','interum_sum']].copy()\n",
        "\n",
        "#Add Variability and Sum of variable terms\n",
        "  newdf = AddVarGen(newdf, parameters, PB, variability_types, replicate)\n",
        "  newdf = AddSum(newdf)\n",
        "\n",
        "#Calculate LDL-C, non-HDL-C and PCE and determine risk groups\n",
        "  newdf = Calcs(newdf)\n",
        "  newdf = Groups(newdf)\n",
        "\n",
        "  return newdf"
      ],
      "metadata": {
        "id": "kWr5iayQPRHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7. Cross-tabulate new risk groups against original risk groups."
      ],
      "metadata": {
        "id": "dv3z4OeCKYFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def List_XT(dfList, group):\n",
        "  \"\"\"This function creates a list of dataframes created by cross-tabulation of the new risk group against the original risk group.\n",
        "  Rows excluded from new dataframes due to lipid measurements <0 or TG >400, also excluded from df0 here for cross-tabulation\"\"\"\n",
        "\n",
        "  XTList = []\n",
        "  for df in dfList:\n",
        "    XT = pd.DataFrame(pd.crosstab(df[group], df0[group], normalize = True))\n",
        "    XTList.append(XT)\n",
        "    \n",
        "  return XTList"
      ],
      "metadata": {
        "id": "1WIASyPx-G9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8. Calculate the total reclassification across all groups for each cross-tabulation."
      ],
      "metadata": {
        "id": "v_RqLtREKn_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ReClass(XTList):\n",
        "  \"\"\"This function calculates the percentage of individuals that were reclassified due to the added error\n",
        "  and makes a list of those percentages for each of the seven errors added.\n",
        "  It also makes a list of the cross-tabulations.\"\"\"\n",
        "\n",
        "  TotalRC = []\n",
        "  for df in XTList:\n",
        "    total_reclassified = round(100*(1-df.loc['A','A']-df.loc['B','B']-df.loc['C','C']-df.loc['D','D']), ndigits=1)\n",
        "    TotalRC.append(total_reclassified)\n",
        "\n",
        "  return TotalRC"
      ],
      "metadata": {
        "id": "IAe8DZzfv4aT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##9. Describe the distribution of reclassifications into each group given 50 (or any number of) replicates."
      ],
      "metadata": {
        "id": "FCdd_gplK9j1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def AveReclass(dfList):\n",
        "  \"\"\"This function concatenates all replicates of cross-tabulation and finds the means for each cell.\"\"\"\n",
        "\n",
        "  loXT_means = []\n",
        "  for l in dfList:\n",
        "    XT_concat = pd.concat(l)\n",
        "    XT_group = XT_concat.groupby(XT_concat.index)\n",
        "    XT_means_dict = XT_group.mean()\n",
        "    XT_means = pd.DataFrame(XT_means_dict)\n",
        "    loXT_means.append(XT_means)\n",
        "\n",
        "  return loXT_means"
      ],
      "metadata": {
        "id": "ccBNISgbGPoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEW LIPID RESULTS: STEPS 1-7"
      ],
      "metadata": {
        "id": "ijiSJvLN2g2R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create global dataframes and lists for analysis"
      ],
      "metadata": {
        "id": "tVrGlMYzL5Ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfnames = ('df1','df2','df3','df4','df5','df6','df7')\n",
        "XTfilenames = ('XT1', 'XT2', 'XT3', 'XT4', 'XT5', 'XT6', 'XT7')"
      ],
      "metadata": {
        "id": "hkCen_AmfNsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps = {'Step': np.arange(1,8), 'Criteria': 'new', 'Scenario': [0.0,0.1,0.2,1.1,1.2,2.1,2.2], \n",
        "           'Error Added': ['BV', 'CV', 'BV + CV', 'PB1 + CV', 'PB1 + BV + CV', 'PB2 + CV', 'PB2 + BV + CV']}\n",
        "Error_L = pd.DataFrame(steps)\n",
        "Error_N = pd.DataFrame(steps)"
      ],
      "metadata": {
        "id": "-P1oflK9FuZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L_List = [[], [], [], [], [], [], []]\n",
        "N_List = [[], [], [], [], [], [], []]"
      ],
      "metadata": {
        "id": "fyK7lpUBvwum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform analysis X times\n",
        "\n",
        "(I have done X = 50. This involves generating 50 random numbers.)"
      ],
      "metadata": {
        "id": "NcxetnvrMKCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make directories"
      ],
      "metadata": {
        "id": "SkUe99AIv-5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in tqdm(range(50)):\n",
        "\n",
        "\n",
        "#Create 7 new databases with different error added to lipid panel, and then calculate new risk scores and risk groups.\n",
        "\n",
        "  df1 = AddCols(df_base, params, 0, ['BV'], m)\n",
        "  df2 = AddCols(df_base, params, 0, ['CV'], m)\n",
        "  df3 = AddCols(df_base, params, 0, ['BV', 'CV'], m)\n",
        "  df4 = AddCols(df_base, params, 1, ['CV'], m)\n",
        "  df5 = AddCols(df_base, params, 1, ['BV','CV'], m)\n",
        "  df6 = AddCols(df_base, params, 2, ['CV'], m)\n",
        "  df7 = AddCols(df_base, params, 2, ['BV','CV'], m)\n",
        "\n",
        "  lodf = [df1, df2, df3, df4, df5, df6, df7]\n",
        "\n",
        "#Create sets of 7 cross-tabulations between new and old risk groups based on LDL-C or non-HDL-C\n",
        "  XTList_L = List_XT(lodf, 'Lgroup')\n",
        "  XTList_N = List_XT(lodf, 'Ngroup')\n",
        "\n",
        "#Create a dataframe showing the total reclassifications due to 7 error sub-scenarios, with a new column for each replicate analysis\n",
        "  Error_L[f'ReClassd_{m+1}'] = ReClass(XTList_L)\n",
        "  Error_N[f'ReClassd_{m+1}'] = ReClass(XTList_N)\n",
        "\n",
        "#Create sets of 50 replicate across-tabulations for each of 7 error sub-scenarios, based on LDL-C or non-HDL-C\n",
        "  for l,x in zip(L_List, XTList_L):\n",
        "    l.append(x)\n",
        "\n",
        "  for l,x in zip(N_List, XTList_N):\n",
        "    l.append(x)\n",
        "  \n",
        "#Save non-global dataframes to .csv files\n",
        "  n = m+1  \n",
        "\n",
        "  for df,b in zip(lodf,dfnames):\n",
        "    df.to_csv(f'New_Criteria/{b}/{b}_{n}.csv')\n",
        "  \n",
        "  for x,y,a in zip(XTList_L, XTList_N, XTfilenames):\n",
        "    x.to_csv(f'New_Criteria/{a}/{a}L_{n}.csv')\n",
        "    y.to_csv(f'New_Criteria/{a}/{a}N_{n}.csv')"
      ],
      "metadata": {
        "id": "wm9O0U9tN9S9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd734d6-f891-4bfe-db60-c1072b06074a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [02:16<00:00,  2.73s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save global dataframes to .CSV files"
      ],
      "metadata": {
        "id": "AFo1V_Bk_uya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Error_L['max'] = Error_L.iloc[:,4:].max(axis=1)\n",
        "Error_L['min'] = Error_L.iloc[:,4:].min(axis=1)\n",
        "Error_N['max'] = Error_N.iloc[:,4:].max(axis=1)\n",
        "Error_N['min'] = Error_N.iloc[:,4:].min(axis=1)"
      ],
      "metadata": {
        "id": "YtwfbWxXO_9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Error_L.to_csv('New_Criteria/Error/errorL.csv', index = False)\n",
        "Error_N.to_csv('New_Criteria/Error/errorN.csv', index = False)"
      ],
      "metadata": {
        "id": "g7CVfc2NraLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loXT_means_L = AveReclass(L_List)\n",
        "loXT_means_N = AveReclass(N_List)\n",
        "for l,n,s in zip(loXT_means_L, loXT_means_N, range(1,8)):\n",
        "  l.to_csv(f'New_Criteria/Stats/L{s}_means.csv')\n",
        "  n.to_csv(f'New_Criteria/Stats/N{s}_means.csv')"
      ],
      "metadata": {
        "id": "F_eVoocfvElb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}